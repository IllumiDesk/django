{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras + Tensorflow Example: Pixel Regression with GPU\n",
    "\n",
    "## Can we recover an image by learning a deep regression map from pixels $(x,y)$ to colors $(r,g,b)$?\n",
    "\n",
    "You bet! The idea is to use a deep learning (DL) solution to do a deep regression to learn a mapping between pixel locations and RGB colors, with the goal of generating an image one pixel at a time. This means that if the dimensions of the target image are X-by-Y, then it is necessary to run the network X*Y. If the image is 100-by-100, then 10,000 training iterations are executed.\n",
    "\n",
    "**Keras with TensorFlow** as a backend creates a working model for this project. Pythonistas rejoice: Keras functional API is a great abstraction for several **Deep Learning** frameworks including Tensorflow to help define complex models, such as multi-output models, directed acyclic graphs, or models with shared layers.\n",
    "\n",
    "The Sequential model is probably a better choice to implement such a network, but it helps to start with something surprisingly simple.\n",
    "\n",
    "Using the Model class:\n",
    "\n",
    "- A layer instance is callable (on a tensor), and it returns a tensor.\n",
    "- Input tensor(s) and output tensor(s) can then be used to define a model.\n",
    "- Such a model can be trained using the Keras Sequential models.\n",
    "\n",
    "Our target image will be the Mona Lisa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Get Started!\n",
    "\n",
    "First, lets use **matplotlib** to import and render the Mona Lisa from a standard *jpg format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "im = mpimg.imread(\"monalisa.jpg\")\n",
    "\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Data\n",
    "\n",
    "Our **training** dataset will be composed of pixels locations and input and pixel values as output are used for **validation**. Here we are loop through the image shape and create floating point arrays for a two dimensional matrix of where the pixels are located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "for i in range(im.shape[0]):\n",
    "    for j in range(im.shape[1]):\n",
    "        X_train.append([float(i),float(j)])\n",
    "        Y_train.append(im[i][j])\n",
    "        \n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "print('Samples:', X_train.shape[0])\n",
    "print('(x,y):', X_train[0],'\\n', '(r,g,b):',Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective \n",
    "\n",
    "Our objective is to create a model that is able to reconstruct the image in R, G, B format.\n",
    "\n",
    "There is a lot of information about Keras and Tensorflow options online. To keep this example simple, let's just assume some standard ways of defining the model:\n",
    "\n",
    "- **Keras Sequential**: a linear stack of layers. We do this by passing a list of layer instances to the constructor.\n",
    "- **Add Layers**: here we are using the standard add() method to add additional layers.\n",
    "- **Define Input Shape**: we will use the Dense 2D layer and define it as a 2D shape with the *input_dim* parameter.\n",
    "\n",
    "This example uses a \"plain vanilla\" neural network, known as [MLP for binary classification](https://keras.io/getting-started/sequential-model-guide/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(500, kernel_initializer=\"uniform\", input_dim=2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(500, kernel_initializer=\"uniform\", input_dim=2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(500, kernel_initializer=\"uniform\", input_dim=2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(500, kernel_initializer=\"uniform\", input_dim=2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(500, kernel_initializer=\"uniform\", input_dim=2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(3, kernel_initializer=\"uniform\", input_dim=2))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Why use Adam Optimizer?\n",
    "# Kingma et al. [1] show that its bias-correction helps Adam slightly outperform RMSprop \n",
    "# towards the end of optimization as gradients become sparser. Insofar, Adam might be the best overall choice.\n",
    "# [1]Kingma, D. P., & Ba, J. L. (2015). Adam: a Method for Stochastic Optimization. \n",
    "# International Conference on Learning Representations, 1â€“13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to find the best model architecture\n",
    "model.fit(X_train, Y_train, epochs=1000, shuffle=True, verbose=1, batch_size=500)\n",
    "Y = model.predict(X_train, batch_size=10000)\n",
    "k = 0\n",
    "im_out = im[:]\n",
    "for i in range(im.shape[0]):\n",
    "    for j in range(im.shape[1]):\n",
    "        im_out[i,j]= Y[k]\n",
    "        k += 1\n",
    "        \n",
    "print(\"Mona Lisa by DL\")\n",
    "plt.imshow(im_out)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im_out)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}